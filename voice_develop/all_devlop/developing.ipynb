{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing...\n",
      "result2:\n",
      "{   'alternative': [   {'confidence': 0.91642207, 'transcript': '枣庄今天的天气怎么样'},\n",
      "                       {'transcript': '镐庄今天的天气怎么样'}],\n",
      "    'final': True}\n",
      "枣庄今天的天气怎么样\n",
      "访问一次网页，耗时：1.0578649044036865\n",
      "枣庄今天晴转多云气温零下5到零上7度~\n"
     ]
    }
   ],
   "source": [
    "# encoding:utf-8\n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    # read the audio data from the default microphone\n",
    "    audio_data = r.record(source, duration=5)\n",
    "    print(\"Recognizing...\")\n",
    "    # convert speech to text\n",
    "    question = r.recognize_google(audio_data,language=\"zh-cn\")\n",
    "    print(question)\n",
    "\n",
    "url = 'https://aip.baidubce.com/rpc/2.0/unit/service/v3/chat?access_token=24.7a069087f696cb7d853f3ee33a4efcbf.2592000.1676606399.282335-29476996' # token id\n",
    "post_data = \"{\\\"version\\\":\\\"3.0\\\",\\\"service_id\\\":\\\"S80122\\\",\\\"session_id\\\":\\\"\\\",\\\"log_id\\\":\\\"1114749\\\",\\\"request\\\":{\\\"terminal_id\\\":\\\"88888\\\",\\\"query\\\":\\\"\" + question +\"\\\"}} \"\n",
    "headers = {'content-type': 'application/x-www-form-urlencoded'}\n",
    "start = time.time()\n",
    "response = requests.post(url, data=post_data.encode('utf-8'), headers=headers)\n",
    "end = time.time()\n",
    "print(f'访问一次网页，耗时：{end - start}')\n",
    "\n",
    "text1 = json.loads(response.text)\n",
    "print(text1['result']['responses'][0]['actions'][0]['say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"query\":\"今天枣庄天气怎么样\"}} \n",
      "\"query\":\"今天枣庄天气怎么样\"}} \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\\"query\\\":\\\"今天枣庄天气怎么样\\\"}} \")\n",
    "\n",
    "print(\"\\\"query\\\":\\\"\" + \"今天枣庄天气怎么样\" +\"\\\"}} \")\n",
    "\"\\\"query\\\":\\\"今天枣庄天气怎么样\\\"}} \" == \"\\\"query\\\":\\\"\" + \"今天枣庄天气怎么样\" +\"\\\"}} \""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voice_to_text(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "访问一次网页，耗时：5.350243806838989\n",
      "并非 更 好 的 心态\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import time\n",
    "filename = \"intent_repeat.wav\"\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    \n",
    "    # recognize (convert from speech to text)\n",
    "    start = time.time()\n",
    "    text = r.recognize_sphinx(audio_data, language='zh-cn')\n",
    "    end = time.time()\n",
    "    print(f'访问一次网页，耗时：{end - start}')\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "\n",
    "def speak(name):\n",
    "    # frequency用来控制语速，去掉试一下就明白了。。。\n",
    "    pygame.mixer.init(frequency=16000, size=0)\n",
    "\n",
    "    pygame.mixer.music.load(name)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        continue\n",
    "    pygame.mixer.music.stop()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    speak(\"result.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'julius' has no attribute 'Client'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22196/1320782576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjulius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjulius\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'localhost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result.wav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'julius' has no attribute 'Client'"
     ]
    }
   ],
   "source": [
    "import julius\n",
    "client = julius.fftconv\n",
    "with open('result.wav', 'rb') as audio:\n",
    "    result = client.recognize(audio)\n",
    "    with open('result.txt','w') as text_file:\n",
    "        text_file.write(result.text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数调用与ip有关，台湾访问时间为2秒，韩国为1秒\n",
    "text = r.recognize_sphinx(audio_data, language='zh-cn')是唯一一个脱机函数，但需要手动安装模型。识别率很差（并非 更 好 的 心态）且时间为5秒;\n",
    "recognize_bing()需要key，注册很麻烦需要国外银行卡，不知道国内能不能用\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing...\n",
      "result2:\n",
      "{   'alternative': [{'confidence': 0.91642207, 'transcript': '你好你好你好你好你好'}],\n",
      "    'final': True}\n",
      "你好你好你好你好你好\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    # read the audio data from the default microphone\n",
    "    audio_data = r.record(source, duration=5)\n",
    "    print(\"Recognizing...\")\n",
    "    # convert speech to text\n",
    "    text = r.recognize_google(audio_data,language=\"zh-cn\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_google(self, audio_data, key=None, language=\"en-US\", pfilter=0, show_all=False, with_confidence=False):\n",
    "    \"\"\"\n",
    "    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Google Speech Recognition API.\n",
    "\n",
    "    The Google Speech Recognition API key is specified by ``key``. If not specified, it uses a generic key that works out of the box. This should generally be used for personal or testing purposes only, as it **may be revoked by Google at any time**.\n",
    "\n",
    "    To obtain your own API key, simply following the steps on the `API Keys <http://www.chromium.org/developers/how-tos/api-keys>`__ page at the Chromium Developers site. In the Google Developers Console, Google Speech Recognition is listed as \"Speech API\".\n",
    "\n",
    "    The recognition language is determined by ``language``, an RFC5646 language tag like ``\"en-US\"`` (US English) or ``\"fr-FR\"`` (International French), defaulting to US English. A list of supported language tags can be found in this `StackOverflow answer <http://stackoverflow.com/a/14302134>`__.\n",
    "\n",
    "    The profanity filter level can be adjusted with ``pfilter``: 0 - No filter, 1 - Only shows the first character and replaces the rest with asterisks. The default is level 0.\n",
    "\n",
    "    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the raw API response as a JSON dictionary.\n",
    "\n",
    "    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n",
    "    \"\"\"\n",
    "    assert isinstance(audio_data, AudioData), \"``audio_data`` must be audio data\"\n",
    "    assert key is None or isinstance(key, str), \"``key`` must be ``None`` or a string\"\n",
    "    assert isinstance(language, str), \"``language`` must be a string\"\n",
    "\n",
    "    flac_data = audio_data.get_flac_data(\n",
    "        convert_rate=None if audio_data.sample_rate >= 8000 else 8000,  # audio samples must be at least 8 kHz\n",
    "        convert_width=2  # audio samples must be 16-bit\n",
    "    )\n",
    "    if key is None: key = \"AIzaSyBOti4mM-6x9WDnZIjIeyEU21OpBXqWBgw\"\n",
    "    url = \"http://www.google.com/speech-api/v2/recognize?{}\".format(urlencode({\n",
    "        \"client\": \"chromium\",\n",
    "        \"lang\": language,\n",
    "        \"key\": key,\n",
    "        \"pFilter\": pfilter\n",
    "    }))\n",
    "    request = Request(url, data=flac_data, headers={\"Content-Type\": \"audio/x-flac; rate={}\".format(audio_data.sample_rate)})\n",
    "\n",
    "    # obtain audio transcription results\n",
    "    try:\n",
    "        response = urlopen(request, timeout=self.operation_timeout)\n",
    "    except HTTPError as e:\n",
    "        raise RequestError(\"recognition request failed: {}\".format(e.reason))\n",
    "    except URLError as e:\n",
    "        raise RequestError(\"recognition connection failed: {}\".format(e.reason))\n",
    "    response_text = response.read().decode(\"utf-8\")\n",
    "    # print('response_text:')\n",
    "    # pprint(response_text, indent=4)\n",
    "\n",
    "    # ignore any blank blocks\n",
    "    actual_result = []\n",
    "    for line in response_text.split(\"\\n\"):\n",
    "        if not line: continue\n",
    "        result = json.loads(line)[\"result\"]            \n",
    "        # print('result1:')\n",
    "        # pprint(result, indent=4)\n",
    "        if len(result) != 0:\n",
    "            actual_result = result[0]\n",
    "            break\n",
    "\n",
    "    # return results\n",
    "    if show_all:\n",
    "        return actual_result\n",
    "    print('result2:')\n",
    "    pprint(actual_result, indent=4)\n",
    "    if not isinstance(actual_result, dict) or len(actual_result.get(\"alternative\", [])) == 0: raise UnknownValueError()\n",
    "\n",
    "    if \"confidence\" in actual_result[\"alternative\"]:\n",
    "        # return alternative with highest confidence score\n",
    "        best_hypothesis = max(actual_result[\"alternative\"], key=lambda alternative: alternative[\"confidence\"])\n",
    "    else:\n",
    "        # when there is no confidence available, we arbitrarily choose the first hypothesis.\n",
    "        best_hypothesis = actual_result[\"alternative\"][0]\n",
    "    if \"transcript\" not in best_hypothesis: raise UnknownValueError()\n",
    "    # https://cloud.google.com/speech-to-text/docs/basics#confidence-values\n",
    "    # \"Your code should not require the confidence field as it is not guaranteed to be accurate, or even set, in any of the results.\"\n",
    "    confidence = best_hypothesis.get(\"confidence\", 0.5)\n",
    "    if with_confidence:\n",
    "        return best_hypothesis[\"transcript\"], confidence\n",
    "    return best_hypothesis[\"transcript\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a23257344542c70b70a498512f46db94a3a7f44d371a6893c689768adca66338"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
